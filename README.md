# DATA WEBSCRAPING PROJECTS - WIKIPEDIA & AMAZON

**Wikipedia Web Scraping**

**Objective**: The goal was to extract structured data about billionaires from a Wikipedia page. This involved pulling information such as names, net worth, and sources of wealth from a comprehensive list available on the site.

**Tools Used:**

**Beautiful Soup:** Used for parsing HTML and XML documents to navigate the web page's structure.
**Requests:** Employed to make HTTP requests to retrieve the Wikipedia page.
**Pandas:** Utilized to organize the scraped data into a structured DataFrame.
**CSV Module:** Used to save the structured data into a CSV file for easy accessibility and use in other applications.

**Amazon Web Scraping**

**Objective:** The goal here was to scrape details of Monitor product from Amazon such as price, descriptions,rating, review count,Display size , Resolution & URL of each Moniotr product.

**Tools Used:**

**Selenium:** Employed for navigating the dynamic content of Amazon's web pages, which often include JavaScript that must be executed to view complete page content.
**BeautifulSoup:** Used to parse the HTML content retrieved via Selenium.
**Pandas:** To structure the extracted data effectively.
**chromedriver_autoinstaller:** Automatically installs and updates the Chrome driver required for Selenium to interact with the web browser.

